{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cl9noTow39vM",
        "outputId": "fcb99801-6d87-4624-d6af-6629aa546c9c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.7243 - loss: 0.8139 - val_accuracy: 0.9317 - val_loss: 0.2478\n",
            "Epoch 2/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.9333 - loss: 0.2280 - val_accuracy: 0.9515 - val_loss: 0.1602\n",
            "Epoch 3/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.9519 - loss: 0.1678 - val_accuracy: 0.9590 - val_loss: 0.1425\n",
            "Epoch 4/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.9554 - loss: 0.1534 - val_accuracy: 0.9638 - val_loss: 0.1233\n",
            "Epoch 5/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.9615 - loss: 0.1341 - val_accuracy: 0.9506 - val_loss: 0.1657\n",
            "Epoch 6/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.9607 - loss: 0.1417 - val_accuracy: 0.9632 - val_loss: 0.1437\n",
            "Epoch 7/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.9643 - loss: 0.1309 - val_accuracy: 0.9634 - val_loss: 0.1367\n",
            "Epoch 8/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.9683 - loss: 0.1100 - val_accuracy: 0.9684 - val_loss: 0.1242\n",
            "Epoch 9/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.1084 - val_accuracy: 0.9751 - val_loss: 0.0931\n",
            "Epoch 10/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.9730 - loss: 0.0971 - val_accuracy: 0.9584 - val_loss: 0.1470\n",
            "313/313 - 2s - 5ms/step - accuracy: 0.9578 - loss: 0.1497\n",
            "Test loss: 0.14974887669086456, Test accuracy: 0.96\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Flatten, Dense\n",
        "\n",
        "#LOAD THE MNIST DATASET\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "#Normalize\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "#one hot encoded  the labels\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "#RNN expects sequential data, so we treat each row pf the image as a time step\n",
        "timesteps = x_train.shape[1]\n",
        "input_dim = x_train.shape[2]\n",
        "\n",
        "#build the rnn model\n",
        "model = Sequential([\n",
        "    SimpleRNN(128, input_shape=(timesteps, input_dim),activation='relu'),\n",
        "    Dense(64,activation='relu'),\n",
        "    Dense(10,activation='softmax')\n",
        "])\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#train the model\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "#Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1YjfMAT-Mbp",
        "outputId": "80f045bb-61ce-4680-e263-77ec3d8b8dd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Predicted digit: 7, Confidence: 1.00\n"
          ]
        }
      ],
      "source": [
        "# Function to preprocess an input image and predict\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "def predict_image(image_path):\n",
        "    # Load and preprocess the image\n",
        "    img = load_img(image_path, color_mode=\"grayscale\", target_size=(28, 28))  # Convert to grayscale and resize\n",
        "    img_array = img_to_array(img) / 255.0  # Normalize the image\n",
        "    img_array = img_array.reshape(1, 28, 28)  # Reshape to (1, 28, 28) for RNN input\n",
        "\n",
        "    # Predict using the trained model\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_label = np.argmax(predictions)\n",
        "    confidence = predictions[0][predicted_label]\n",
        "\n",
        "    return predicted_label, confidence\n",
        "\n",
        "# Example usage:\n",
        "image_path = \"2.jpg\"  # Replace with the path to your input image\n",
        "predicted_label, confidence = predict_image(image_path)\n",
        "print(f\"Predicted digit: {predicted_label}, Confidence: {confidence:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 899
        },
        "id": "6kQqjM6xAwYb",
        "outputId": "1c9c2cc9-143e-486a-d60c-c7cbd766c90c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.7102 - loss: 0.8653 - val_accuracy: 0.9388 - val_loss: 0.2079\n",
            "Epoch 2/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - accuracy: 0.9306 - loss: 0.2390 - val_accuracy: 0.9516 - val_loss: 0.1820\n",
            "Epoch 3/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.9472 - loss: 0.1848 - val_accuracy: 0.9604 - val_loss: 0.1461\n",
            "Epoch 4/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9560 - loss: 0.1546 - val_accuracy: 0.9597 - val_loss: 0.1535\n",
            "Epoch 5/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9625 - loss: 0.1357 - val_accuracy: 0.9739 - val_loss: 0.1047\n",
            "Epoch 6/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - accuracy: 0.9636 - loss: 0.1292 - val_accuracy: 0.9709 - val_loss: 0.1040\n",
            "Epoch 7/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - accuracy: 0.9660 - loss: 0.1221 - val_accuracy: 0.9646 - val_loss: 0.1328\n",
            "Epoch 8/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9691 - loss: 0.1109 - val_accuracy: 0.9705 - val_loss: 0.1125\n",
            "Epoch 9/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.9659 - loss: 0.1189 - val_accuracy: 0.9669 - val_loss: 0.1219\n",
            "Epoch 10/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.9710 - loss: 0.1026 - val_accuracy: 0.9683 - val_loss: 0.1337\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.9655 - loss: 0.1322\n",
            "Test accuracy: 0.97\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted digit: 7, Confidence: 0.99\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import matplotlib.pyplot as plt  # Import for displaying the image\n",
        "\n",
        "# LOAD THE MNIST DATASET\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "timesteps = x_train.shape[1]\n",
        "input_dim = x_train.shape[2]\n",
        "\n",
        "# Build the RNN\n",
        "model = Sequential([\n",
        "    SimpleRNN(128, input_shape=(timesteps, input_dim), activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Test accuracy: {test_accuracy:.2f}\")\n",
        "\n",
        "# Function to preprocess an input image and predict\n",
        "def predict_image(image_path):\n",
        "    # Load and preprocess the image\n",
        "    img = load_img(image_path, color_mode=\"grayscale\", target_size=(28, 28))  # Convert to grayscale and resize\n",
        "    img_array = img_to_array(img) / 255.0  # Normalize the image\n",
        "    img_array = img_array.reshape(1, 28, 28)  # Reshape to (1, 28, 28) for RNN input\n",
        "\n",
        "   \n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_label = np.argmax(predictions)\n",
        "    confidence = predictions[0][predicted_label]\n",
        "\n",
        "  \n",
        "    plt.imshow(img_array.reshape(28, 28), cmap='gray')  \n",
        "    plt.title(f\"Predicted: {predicted_label}, Confidence: {confidence:.2f}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    return predicted_label, confidence\n",
        "#example\n",
        "image_path = \"7.jpg\"  \n",
        "predicted_label, confidence = predict_image(image_path)\n",
        "print(f\"Predicted digit: {predicted_label}, Confidence: {confidence:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwwSND6sBBCY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
